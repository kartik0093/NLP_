{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os, sys\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "LSTM_NODES =512\n",
    "NUM_SENTENCES = 30000\n",
    "MAX_SENTENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 30000\n",
    "EMBEDDING_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sample input: 30000\n",
      "Number of sample output: 30000\n",
      "Number of sample output input: 30000\n"
     ]
    }
   ],
   "source": [
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "\n",
    "count = 0\n",
    "for line in open('fra.txt', encoding=\"utf-8\"):\n",
    "    count += 1\n",
    "    if count > NUM_SENTENCES:\n",
    "        break\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    input_sentence = line.rstrip().split('\\t')[0]\n",
    "    output = line.rstrip().split('\\t')[1]\n",
    "\n",
    "    output_sentence = output + ' <eos>'\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Number of sample input:\", len(input_sentences))\n",
    "print(\"Number of sample output:\", len(output_sentences))\n",
    "print(\"Number of sample output input:\", len(output_sentences_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentence:  Beat it.\n",
      "French translation:  Casse-toi de là. <eos>\n"
     ]
    }
   ],
   "source": [
    "print(\"English sentence: \",input_sentences[180])\n",
    "print(\"French translation: \",output_sentences[180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19], [19], [19], [770], [770]]\n"
     ]
    }
   ],
   "source": [
    "#tokenize the input sentences(input language) \n",
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "print(input_integer_seq[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the input: 4467\n"
     ]
    }
   ],
   "source": [
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print('Total unique words in the input: %s' % len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of longest sentence in input: 6\n"
     ]
    }
   ],
   "source": [
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Length of longest sentence in input: %g\" % max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences.shape: (30000, 6)\n",
      "encoder_input_sequences[180]: [  0   0   0   0 383   6]\n"
     ]
    }
   ],
   "source": [
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences.shape:\", encoder_input_sequences.shape)\n",
    "print(\"encoder_input_sequences[180]:\", encoder_input_sequences[180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print(word2idx_inputs[\"join\"])\n",
    "print(word2idx_inputs[\"us\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 61, 6], [2, 816], [2, 639, 6], [2, 1370, 6], [2, 6191]]\n"
     ]
    }
   ],
   "source": [
    "#tokenize the output sentences(Output language)\n",
    "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "print(output_input_integer_seq[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the output: 12596\n"
     ]
    }
   ],
   "source": [
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print('Total unique words in the output: %s' % len(word2idx_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of longest sentence in the output: 13\n"
     ]
    }
   ],
   "source": [
    "num_words_output = len(word2idx_outputs) + 1\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_input_sequences.shape: (30000, 13)\n",
      "decoder_input_sequences[180]: [   2 6237    9  153    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences.shape:\", decoder_input_sequences.shape)\n",
    "print(\"decoder_input_sequences[180]:\", decoder_input_sequences[180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3890\n",
      "18\n",
      "234\n"
     ]
    }
   ],
   "source": [
    "print(word2idx_outputs[\"<sos>\"])\n",
    "print(word2idx_outputs[\"joignez-vous\"])\n",
    "print(word2idx_outputs[\"à\"])\n",
    "print(word2idx_outputs[\"nous.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output_sequences.shape: (30000, 13)\n"
     ]
    }
   ],
   "source": [
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_output_sequences.shape:\", decoder_output_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_file = open('C:/Users/karthick/Downloads/glove.6B.100d.txt/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = zeros((num_words, EMBEDDING_SIZE))\n",
    "for word, index in word2idx_inputs.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12648    0.1366     0.22192   -0.025204  -0.7197     0.66147\n",
      "  0.48509    0.057223   0.13829   -0.26375   -0.23647    0.74349\n",
      "  0.46737   -0.462      0.20031   -0.26302    0.093948  -0.61756\n",
      " -0.28213    0.1353     0.28213    0.21813    0.16418    0.22547\n",
      " -0.98945    0.29624   -0.62476   -0.29535    0.21534    0.92274\n",
      "  0.38388    0.55744   -0.14628   -0.15674   -0.51941    0.25629\n",
      " -0.0079678  0.12998   -0.029192   0.20868   -0.55127    0.075353\n",
      "  0.44746   -0.71046    0.75562    0.010378   0.095229   0.16673\n",
      "  0.22073   -0.46562   -0.10199   -0.80386    0.45162    0.45183\n",
      "  0.19869   -1.6571     0.7584    -0.40298    0.82426   -0.386\n",
      "  0.0039546  0.61318    0.02701   -0.3308    -0.095652  -0.082164\n",
      "  0.7858     0.13394   -0.32715   -0.31371   -0.20247   -0.73001\n",
      " -0.49343    0.56445    0.61038    0.36777   -0.070182   0.44859\n",
      " -0.61774   -0.18849    0.65592    0.44797   -0.10469    0.62512\n",
      " -1.9474    -0.60622    0.073874   0.50013   -1.1278    -0.42066\n",
      " -0.37322   -0.50538    0.59171    0.46534   -0.42482    0.83265\n",
      "  0.081548  -0.44147   -0.084311  -1.2304   ]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_dictionary[\"ill\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.014588    0.057711    0.23784     0.038358    0.40990001  0.075356\n",
      "  0.56882    -0.43048    -0.83552003  0.067724    0.54229999 -0.52925003\n",
      "  0.80431002  0.35905001 -0.0044033  -0.87582999  1.07019997 -0.030807\n",
      " -0.54617     0.12723     0.062372    0.45129001  0.20299999  0.22989\n",
      "  0.47604001 -0.65180999 -0.33974001 -1.12179995  1.06330001  0.49349999\n",
      " -0.44218001  0.73657    -0.26374    -0.88155001 -0.73110998  0.27689001\n",
      " -0.69608998  0.62984997  0.44922999  0.36131001 -0.25182    -0.060487\n",
      "  0.63139999 -0.51008999  0.75509     0.37737     0.091904   -0.64363003\n",
      " -0.047406   -0.68154001 -0.026457   -1.44140005 -0.072266    0.39379001\n",
      "  0.27090999 -1.23819995 -0.70762998  0.079198    1.1983      1.00880003\n",
      "  0.14177001 -0.09531     0.24018     0.078879    0.53956997 -0.27958\n",
      "  0.42635     0.62883002 -0.21539     1.28419995  0.15964     0.33737001\n",
      " -0.47059     0.15877999  0.25371999  0.052108   -0.057918    0.37207001\n",
      " -0.1701     -0.57551998  0.70279998 -0.37676001  0.31406999  0.16065\n",
      " -0.42506999 -0.33281001 -0.034163    0.31330001 -0.58266002 -0.66052002\n",
      " -0.12598    -0.79141998  0.0309      0.62607002 -0.49507001  0.36019999\n",
      " -0.13049001  0.39017999 -0.49099001 -0.53837001]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix[539])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_targets_one_hot = np.zeros((\n",
    "        len(input_sentences),\n",
    "        max_out_len,\n",
    "        num_words_output\n",
    "    ),\n",
    "    dtype='uint8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 13, 12597)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(decoder_output_sequences):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(LSTM_NODES, return_state=True)\n",
    "\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "encoder_states = [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
    "\n",
    "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs_placeholder,\n",
    "  decoder_inputs_placeholder], decoder_outputs)\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "211/211 [==============================] - 281s 1s/step - loss: 2.5698 - accuracy: 0.6821 - val_loss: 1.9353 - val_accuracy: 0.7193\n",
      "Epoch 2/20\n",
      "211/211 [==============================] - 644s 3s/step - loss: 1.4154 - accuracy: 0.7876 - val_loss: 1.6689 - val_accuracy: 0.7570\n",
      "Epoch 3/20\n",
      "211/211 [==============================] - 278s 1s/step - loss: 1.1745 - accuracy: 0.8175 - val_loss: 1.5262 - val_accuracy: 0.7747\n",
      "Epoch 4/20\n",
      "211/211 [==============================] - 271s 1s/step - loss: 1.0199 - accuracy: 0.8358 - val_loss: 1.4481 - val_accuracy: 0.7836\n",
      "Epoch 5/20\n",
      "211/211 [==============================] - 279s 1s/step - loss: 0.9009 - accuracy: 0.8502 - val_loss: 1.4054 - val_accuracy: 0.7901\n",
      "Epoch 6/20\n",
      "211/211 [==============================] - 279s 1s/step - loss: 0.8148 - accuracy: 0.8617 - val_loss: 1.3637 - val_accuracy: 0.7940\n",
      "Epoch 7/20\n",
      "211/211 [==============================] - 286s 1s/step - loss: 0.7360 - accuracy: 0.8731 - val_loss: 1.3413 - val_accuracy: 0.7958\n",
      "Epoch 8/20\n",
      "211/211 [==============================] - 315s 1s/step - loss: 0.6724 - accuracy: 0.8819 - val_loss: 1.3423 - val_accuracy: 0.7976\n",
      "Epoch 9/20\n",
      "211/211 [==============================] - 312s 1s/step - loss: 0.6173 - accuracy: 0.8906 - val_loss: 1.3328 - val_accuracy: 0.8002\n",
      "Epoch 10/20\n",
      "211/211 [==============================] - 287s 1s/step - loss: 0.5712 - accuracy: 0.8983 - val_loss: 1.3226 - val_accuracy: 0.8037\n",
      "Epoch 11/20\n",
      "211/211 [==============================] - 285s 1s/step - loss: 0.5300 - accuracy: 0.9052 - val_loss: 1.3445 - val_accuracy: 0.8024\n",
      "Epoch 12/20\n",
      "211/211 [==============================] - 301s 1s/step - loss: 0.4961 - accuracy: 0.9111 - val_loss: 1.3377 - val_accuracy: 0.8022\n",
      "Epoch 13/20\n",
      "211/211 [==============================] - 284s 1s/step - loss: 0.4630 - accuracy: 0.9159 - val_loss: 1.3571 - val_accuracy: 0.8031\n",
      "Epoch 14/20\n",
      "211/211 [==============================] - 268s 1s/step - loss: 0.4365 - accuracy: 0.9195 - val_loss: 1.3337 - val_accuracy: 0.8047\n",
      "Epoch 15/20\n",
      "211/211 [==============================] - 253s 1s/step - loss: 0.4162 - accuracy: 0.9234 - val_loss: 1.3451 - val_accuracy: 0.8047\n",
      "Epoch 16/20\n",
      "211/211 [==============================] - 266s 1s/step - loss: 0.3952 - accuracy: 0.9264 - val_loss: 1.3595 - val_accuracy: 0.8033\n",
      "Epoch 17/20\n",
      "211/211 [==============================] - 266s 1s/step - loss: 0.3773 - accuracy: 0.9292 - val_loss: 1.3746 - val_accuracy: 0.8052\n",
      "Epoch 18/20\n",
      "211/211 [==============================] - 264s 1s/step - loss: 0.3600 - accuracy: 0.9320 - val_loss: 1.3852 - val_accuracy: 0.8033\n",
      "Epoch 19/20\n",
      "211/211 [==============================] - 267s 1s/step - loss: 0.3479 - accuracy: 0.9346 - val_loss: 1.3917 - val_accuracy: 0.8021\n",
      "Epoch 20/20\n",
      "211/211 [==============================] - 280s 1s/step - loss: 0.3337 - accuracy: 0.9358 - val_loss: 1.4129 - val_accuracy: 0.8029\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets_one_hot,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs_placeholder, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(LSTM_NODES,))\n",
    "decoder_state_input_c = Input(shape=(LSTM_NODES,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_states = [h, c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_out_len):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        target_seq[0, 0] = idx\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: Go play in traffic.\n",
      "Response: va au suis !\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "translation = translate_sentence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: Who'll cook?\n",
      "Response: qui va cuisiner.\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "translation = translate_sentence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(LSTM_NODES, return_state=True)\n",
    "\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "encoder_states = [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
    "\n",
    "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "dropout = Dropout(rate=0.3)\n",
    "decoder_outputs = dropout(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizer_v2 import adam \n",
    "model3 = Model([encoder_inputs_placeholder,decoder_inputs_placeholder], decoder_outputs)\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "188/188 [==============================] - 266s 1s/step - loss: 3.3797 - acc: 0.6555 - val_loss: 2.0642 - val_acc: 0.7063\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 260s 1s/step - loss: 1.5325 - acc: 0.7691 - val_loss: 1.7010 - val_acc: 0.7551\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 273s 1s/step - loss: 1.1734 - acc: 0.8151 - val_loss: 1.5207 - val_acc: 0.7767\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 279s 1s/step - loss: 0.9405 - acc: 0.8359 - val_loss: 1.4136 - val_acc: 0.7898\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 258s 1s/step - loss: 0.7535 - acc: 0.8545 - val_loss: 1.3493 - val_acc: 0.8000\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 244s 1s/step - loss: 0.6034 - acc: 0.8721 - val_loss: 1.3063 - val_acc: 0.8067\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 256s 1s/step - loss: 0.4855 - acc: 0.8899 - val_loss: 1.2822 - val_acc: 0.8114\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 253s 1s/step - loss: 0.3898 - acc: 0.9063 - val_loss: 1.2609 - val_acc: 0.8159\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 267s 1s/step - loss: 0.3213 - acc: 0.9193 - val_loss: 1.2603 - val_acc: 0.8178\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 276s 1s/step - loss: 0.2653 - acc: 0.9302 - val_loss: 1.2596 - val_acc: 0.8189\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 265s 1s/step - loss: 0.2279 - acc: 0.9373 - val_loss: 1.2635 - val_acc: 0.8211\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 281s 1s/step - loss: 0.2010 - acc: 0.9417 - val_loss: 1.2694 - val_acc: 0.8210\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 279s 1s/step - loss: 0.1792 - acc: 0.9460 - val_loss: 1.2757 - val_acc: 0.8213\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 281s 1s/step - loss: 0.1630 - acc: 0.9489 - val_loss: 1.2754 - val_acc: 0.8226\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 278s 1s/step - loss: 0.1489 - acc: 0.9517 - val_loss: 1.2854 - val_acc: 0.8226\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 282s 1s/step - loss: 0.1397 - acc: 0.9529 - val_loss: 1.2909 - val_acc: 0.8222\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 579s 3s/step - loss: 0.1310 - acc: 0.9545 - val_loss: 1.3018 - val_acc: 0.8215\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 254s 1s/step - loss: 0.1231 - acc: 0.9556 - val_loss: 1.3053 - val_acc: 0.8227\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 274s 1s/step - loss: 0.1189 - acc: 0.9564 - val_loss: 1.3060 - val_acc: 0.8240\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 260s 1s/step - loss: 0.1148 - acc: 0.9569 - val_loss: 1.3128 - val_acc: 0.8232\n"
     ]
    }
   ],
   "source": [
    "r = model3.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets_one_hot,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entire model to a HDFS file\n",
    "model3.save(\"Encoder-decoder_Model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
